{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "def train_sequential_model(X_train_scaled, y_train_scaled, X_test_scaled, y_test_scaled, time_steps=30):\n",
    "    \"\"\"\n",
    "    Train a Sequential LSTM model for time series prediction.\n",
    "    \"\"\"\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
    "    from tensorflow.keras.callbacks import EarlyStopping\n",
    "    import numpy as np\n",
    "    \n",
    "    print(\"Starting sequential model training...\")\n",
    "    \n",
    "    try:\n",
    "        print(f\"Input shapes - X_train: {X_train_scaled.shape}, X_test: {X_test_scaled.shape}\")\n",
    "        \n",
    "        # Check if we have enough data for the sequence length\n",
    "        if len(X_train_scaled) <= time_steps or len(X_test_scaled) <= time_steps:\n",
    "            print(f\"Warning: Not enough data for time_steps={time_steps}. Reducing time_steps.\")\n",
    "            time_steps = min(len(X_train_scaled) // 2, len(X_test_scaled) // 2, 20)\n",
    "            print(f\"Adjusted time_steps to {time_steps}\")\n",
    "        \n",
    "        print(\"Creating training sequences...\")\n",
    "        # Reshape data for LSTM [samples, time_steps, features]\n",
    "        X_train_seq, y_train_seq = [], []\n",
    "        for i in range(time_steps, len(X_train_scaled)):\n",
    "            X_train_seq.append(X_train_scaled[i-time_steps:i])\n",
    "            y_train_seq.append(y_train_scaled[i])\n",
    "        \n",
    "        X_train_seq = np.array(X_train_seq)\n",
    "        y_train_seq = np.array(y_train_seq)\n",
    "        print(f\"Training sequences created. X_train_seq shape: {X_train_seq.shape}\")\n",
    "        \n",
    "        print(\"Creating test sequences...\")\n",
    "        # Prepare test data in the same way\n",
    "        X_test_seq, y_test_seq = [], []\n",
    "        for i in range(time_steps, len(X_test_scaled)):\n",
    "            X_test_seq.append(X_test_scaled[i-time_steps:i])\n",
    "            y_test_seq.append(y_test_scaled[i])\n",
    "        \n",
    "        X_test_seq = np.array(X_test_seq)\n",
    "        y_test_seq = np.array(y_test_seq)\n",
    "        print(f\"Test sequences created. X_test_seq shape: {X_test_seq.shape}\")\n",
    "        \n",
    "        # Print shapes for debugging\n",
    "        print(f\"Sequence shapes - X_train: {X_train_seq.shape}, y_train: {y_train_seq.shape}\")\n",
    "        print(f\"Sequence shapes - X_test: {X_test_seq.shape}, y_test: {y_test_seq.shape}\")\n",
    "        \n",
    "        if X_train_seq.shape[0] == 0 or X_test_seq.shape[0] == 0:\n",
    "            raise ValueError(f\"Created empty sequences. Try reducing time_steps (currently {time_steps}).\")\n",
    "        \n",
    "        # Get the number of features\n",
    "        n_features = X_train_scaled.shape[1]\n",
    "        print(f\"Number of features: {n_features}\")\n",
    "        \n",
    "        print(\"Building model...\")\n",
    "        # Build the model\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(units=50, return_sequences=True, input_shape=(time_steps, n_features)))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(units=50, return_sequences=True))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(units=50, return_sequences=True))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(units=50))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(1))\n",
    "        \n",
    "        print(\"Compiling model...\")\n",
    "        # Use run_eagerly=True to get better error messages\n",
    "        model.compile(optimizer='adam', loss='mean_squared_error', run_eagerly=True)\n",
    "        \n",
    "        # Early stopping to prevent overfitting\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            mode='min',\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        print(\"Training model...\")\n",
    "        # Train the model\n",
    "        history = model.fit(\n",
    "            X_train_seq, y_train_seq,\n",
    "            epochs=50,\n",
    "            batch_size=32,\n",
    "            validation_data=(X_test_seq, y_test_seq),\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        print(\"Model training completed successfully!\")\n",
    "        \n",
    "        best_params = {\n",
    "            'units': 50,\n",
    "            'dropout': 0.2,\n",
    "            'time_steps': time_steps\n",
    "        }\n",
    "        \n",
    "        print(\"Returning model and results...\")\n",
    "        return model, history, X_test_seq, y_test_seq, best_params\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR in train_sequential_model: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        # Return None values to indicate an error\n",
    "        return None, None, None, None, None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
