{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Union, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def add_lags(df, target_col='Close', n_lags=30):\n",
    "    \"\"\"\n",
    "    Adds lag features to the dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame containing the data.\n",
    "    - target_col: The column for which lags will be created.\n",
    "    - n_lags: Number of lag features to create.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with lag features added.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df_copy = df.copy()\n",
    "        for lag in range(1, n_lags + 1):\n",
    "            df_copy[f'{target_col}_lag_{lag}'] = df_copy[target_col].shift(lag)\n",
    "        return df_copy.dropna()\n",
    "    except Exception as e:\n",
    "        print(f\"Error in add_lags: {e}\")\n",
    "        raise\n",
    "\n",
    "def add_technical_indicators(df):\n",
    "    \"\"\"\n",
    "    Add technical indicators to the DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: Input DataFrame\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with added technical indicators\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Moving averages\n",
    "        df['SMA_5'] = df['Close'].rolling(window=5).mean()\n",
    "        df['SMA_20'] = df['Close'].rolling(window=20).mean()\n",
    "        df['EMA_12'] = df['Close'].ewm(span=12, adjust=False).mean()\n",
    "        df['EMA_26'] = df['Close'].ewm(span=26, adjust=False).mean()\n",
    "        \n",
    "        # RSI\n",
    "        delta = df['Close'].diff()\n",
    "        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "        rs = gain / loss\n",
    "        df['RSI'] = 100 - (100 / (1 + rs))\n",
    "        \n",
    "        # Bollinger Bands\n",
    "        df['20d_std'] = df['Close'].rolling(window=20).std()\n",
    "        df['upper_band'] = df['SMA_20'] + (df['20d_std'] * 2)\n",
    "        df['lower_band'] = df['SMA_20'] - (df['20d_std'] * 2)\n",
    "        \n",
    "        # MACD\n",
    "        df['MACD'] = df['EMA_12'] - df['EMA_26']\n",
    "        df['MACD_signal'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
    "        \n",
    "        # Volatility\n",
    "        df['volatility'] = df['Close'].rolling(window=20).std() / df['Close'].rolling(window=20).mean()\n",
    "        \n",
    "        # Volume features\n",
    "        df['volume_change'] = df['Volume'].pct_change()\n",
    "        df['volume_ma'] = df['Volume'].rolling(window=10).mean()\n",
    "        df['volume_ratio'] = df['Volume'] / df['volume_ma']\n",
    "        \n",
    "        # Price to moving average ratios\n",
    "        for horizon in [2, 5, 60, 250]:\n",
    "            rolling_averages = df['Close'].rolling(window=horizon).mean()\n",
    "            df[f'Close_ratio_{horizon}d_MA'] = df['Close'] / rolling_averages\n",
    "            \n",
    "            # Trend features\n",
    "            df[f'Trend_{horizon}d_MA'] = df['GreenDay'].shift(1).rolling(window=horizon).sum()\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error in add_technical_indicators: {e}\")\n",
    "        raise\n",
    "\n",
    "def add_seasonal_features(df):\n",
    "    \"\"\"\n",
    "    Add seasonal features to the DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: Input DataFrame\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with added seasonal features\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ensure index is datetime\n",
    "        if not isinstance(df.index, pd.DatetimeIndex):\n",
    "            df.index = pd.to_datetime(df.index)\n",
    "        \n",
    "        df['day_of_week'] = df.index.dayofweek\n",
    "        df['month'] = df.index.month\n",
    "        df['quarter'] = df.index.quarter\n",
    "        \n",
    "        # One-hot encode day of week and month\n",
    "        for day in range(5):  # 0-4 for weekdays\n",
    "            df[f'day_{day}'] = (df['day_of_week'] == day).astype(int)\n",
    "        \n",
    "        for month in range(1, 13):\n",
    "            df[f'month_{month}'] = (df['month'] == month).astype(int)\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error in add_seasonal_features: {e}\")\n",
    "        raise\n",
    "\n",
    "def feature_engineering(data, custom_horizons=None):\n",
    "    \"\"\"\n",
    "    Comprehensive feature engineering function.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: Input DataFrame\n",
    "    - custom_horizons: Optional list of custom horizons to use\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with engineered features\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use custom horizons if provided, otherwise use default\n",
    "        horizons = custom_horizons or [2, 5, 60, 250]\n",
    "        \n",
    "        # Ensure data is a copy to avoid modifying original\n",
    "        data = data.copy()\n",
    "        \n",
    "        # Validate required columns\n",
    "        required_columns = ['Close', 'Volume', 'GreenDay']\n",
    "        for col in required_columns:\n",
    "            if col not in data.columns:\n",
    "                raise ValueError(f\"Missing required column: {col}\")\n",
    "        \n",
    "        # Prepare new predictors\n",
    "        new_predictors = []\n",
    "        for horizon in horizons:\n",
    "            rolling_averages = data['Close'].rolling(window=horizon).mean()\n",
    "            ratio_column = f'Close_ratio_{horizon}d MA'\n",
    "            data[ratio_column] = data['Close'] / rolling_averages\n",
    "            trend_column = f'Trend_{horizon}d MA'\n",
    "            data[trend_column] = data['GreenDay'].shift(1).rolling(window=horizon).sum()\n",
    "            new_predictors.extend([ratio_column, trend_column])\n",
    "        \n",
    "        # Add features\n",
    "        data = add_lags(data, target_col='Close', n_lags=30)\n",
    "        data = add_technical_indicators(data)\n",
    "        data = add_seasonal_features(data)\n",
    "        \n",
    "        # Drop rows with NaN values\n",
    "        data = data.dropna()\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in feature_engineering: {e}\")\n",
    "        raise\n",
    "\n",
    "def scale_data(X_train, X_test, y_train, y_test, feature_scaler=None, target_scaler=None):\n",
    "    \"\"\"\n",
    "    Scale features and target variables.\n",
    "    \n",
    "    Parameters:\n",
    "    - X_train: Training features\n",
    "    - X_test: Test features\n",
    "    - y_train: Training target\n",
    "    - y_test: Test target\n",
    "    - feature_scaler: Optional pre-fitted feature scaler\n",
    "    - target_scaler: Optional pre-fitted target scaler\n",
    "    \n",
    "    Returns:\n",
    "    - Scaled training and test data, along with scalers\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use RobustScaler to handle outliers\n",
    "        if feature_scaler is None:\n",
    "            feature_scaler = MinMaxScaler()\n",
    "        \n",
    "        if target_scaler is None:\n",
    "            target_scaler = MinMaxScaler()\n",
    "        \n",
    "        # Fit and transform feature scaler\n",
    "        X_train_scaled = feature_scaler.fit_transform(X_train)\n",
    "        X_test_scaled = feature_scaler.transform(X_test)\n",
    "        \n",
    "        # Fit and transform target scaler\n",
    "        y_train_scaled = target_scaler.fit_transform(y_train)\n",
    "        y_test_scaled = target_scaler.transform(y_test)\n",
    "        \n",
    "        return X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled, feature_scaler, target_scaler\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in scale_data: {e}\")\n",
    "        raise\n",
    "\n",
    "def split_data(data: pd.DataFrame, \n",
    "               train_size: float = 0.8, \n",
    "               shuffle: bool = False, \n",
    "               random_state: int = None) -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:\n",
    "    \"\"\"\n",
    "    Split data into training and testing sets with enhanced flexibility.\n",
    "    \n",
    "    Args:\n",
    "        data (DataFrame): Data to split.\n",
    "        train_size (float): Proportion of data to use for training (0.0 to 1.0).\n",
    "        shuffle (bool): Whether to shuffle the data before splitting.\n",
    "        random_state (int): Seed for random shuffling for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Training and testing sets for X and y.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validate input\n",
    "        if not isinstance(data, pd.DataFrame):\n",
    "            raise ValueError(\"Input must be a pandas DataFrame\")\n",
    "        \n",
    "        if not (0 < train_size < 1):\n",
    "            raise ValueError(\"train_size must be between 0 and 1\")\n",
    "        \n",
    "        # Ensure 'Close' column exists\n",
    "        if 'Close' not in data.columns:\n",
    "            raise ValueError(\"DataFrame must contain a 'Close' column\")\n",
    "        \n",
    "        # Create a copy to avoid modifying the original data\n",
    "        data_copy = data.copy()\n",
    "        \n",
    "        # Shuffle if requested\n",
    "        if shuffle:\n",
    "            data_copy = data_copy.sample(frac=1, random_state=random_state)\n",
    "        \n",
    "        # Split the data\n",
    "        train_size_index = int(len(data_copy) * train_size)\n",
    "        \n",
    "        # Split features and target\n",
    "        X = data_copy.drop(columns=['Close'])\n",
    "        y = data_copy['Close']\n",
    "        \n",
    "        # Split into training and testing sets\n",
    "        X_train, X_test = X[:train_size_index], X[train_size_index:]\n",
    "        y_train, y_test = y[:train_size_index], y[train_size_index:]\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in split_data: {e}\")\n",
    "        raise\n",
    "\n",
    "def create_sequences(X: Union[np.ndarray, pd.DataFrame], \n",
    "                     y: Union[np.ndarray, pd.Series], \n",
    "                     time_steps: int = 10) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Transform data into sequences suitable for LSTM models.\n",
    "    \n",
    "    Parameters:\n",
    "    X (array-like): Features\n",
    "    y (array-like): Target\n",
    "    time_steps (int): Number of time steps in each sequence\n",
    "    \n",
    "    Returns:\n",
    "    X_seq, y_seq: Data transformed into sequences\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert to numpy arrays if not already\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        \n",
    "        # Validate inputs\n",
    "        if len(X) <= time_steps:\n",
    "            raise ValueError(f\"Not enough data for {time_steps} time steps\")\n",
    "        \n",
    "        X_seq, y_seq = [], []\n",
    "        for i in range(len(X) - time_steps):\n",
    "            X_seq.append(X[i:i + time_steps])\n",
    "            y_seq.append(y[i + time_steps])\n",
    "        \n",
    "        return np.array(X_seq), np.array(y_seq)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in create_sequences: {e}\")\n",
    "        raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
